# MADRL
### 다중에이전트 강화학습

정보 : [MADRL 슬로우 페이퍼](https://event-us.kr/modu/event/4666)

참가자 : 강효림, 김예찬, 노원종, 박규봉, 배영민, 안홍일, 양홍선, 정재현

퍼실 : 김예찬

## 논문리스트

### 2015
 - **(Review) [Multiagent Cooperation and Competition with Deep Reinforcement Learning(1511)](https://arxiv.org/abs/1511.08779)**
 - **(Review) [Deep Reinforcement Learning in Parameterized Action Space(1511)](https://arxiv.org/pdf/1511.04143.pdf)**

### 2016
 - **(Review) [Learning to Communicate to Solve Riddles with Deep distributed Recurrent Q-Network(1602)](https://arxiv.org/abs/1602.02672)**
 - **(Review) [Deep Reinforcement Learning from Self-Play in Imperfect-Information Games(1603)](https://arxiv.org/abs/1603.01121)**
 - [Opponent Modeling in Deep Reinforcement Learning(1609)](https://arxiv.org/pdf/1609.05559.pdf)
 - **(Review) [Learning to Communicate with Deep Multi-Agent Reinforcement Learning(1605)](https://arxiv.org/abs/1605.06676)**
 - **(Review) [Learning Multiagent Communication with Backpropagation(1605)](https://arxiv.org/abs/1605.07736)**
 - [Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving(1610)](https://arxiv.org/abs/1610.03295)
 - **(Review) [Learning to Play Guess Who? and Inventing a Grounded Language as a Consequence(1611)](https://arxiv.org/abs/1611.03218)**
 - **(Review) [Multi-Agent Cooperation and the Emergence of (Natural) Language(1612)](https://arxiv.org/abs/1612.07182)**

#### 2016 참고
 - [Interaction Networks for Learning about Objects, Relations and Physics(1612)](https://arxiv.org/abs/1612.00222)


### 2017
 - **(Review) [Cooperative Multi-Agent Control using Deep Reinforcement Learning](http://ala2017.it.nuigalway.ie/papers/ALA2017_Gupta.pdf)**
 - **(Review) [Multi-agent Reinforcement Learning in Sequential Social Dilemmas(1702)](https://arxiv.org/abs/1702.03037)**
 - **(Review) [Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning(1702)](https://arxiv.org/abs/1702.08887)**
 - [Coordinated Multi-Agent Imitation Learning(1703)](https://arxiv.org/pdf/1703.03121.pdf)
 - **(Review) [Emergence of Grounded Language in Multi-agent Populations(1703)](https://arxiv.org/abs/1703.04908)**
 - [Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Parital Observability(1703)](https://arxiv.org/abs/1703.06182)
 - **(Review) [Counterfactual Multi-Agent Policy Gradients(1705)](https://arxiv.org/abs/1705.08926)**
 - [Multiagent Bidirectionally-Coordinated Nets Emergence of Human-level Coordination in Learning to Play StarCraft Combat Games(1703)](https://arxiv.org/abs/1703.10069)
 - **(Review) [Emergence of Language with Multi-agent Games: Learning to Communicate with Sequence of Symbols(1705)](https://arxiv.org/abs/1705.11192)**
 - **(Review) [Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments(1706)](https://arxiv.org/abs/1706.02275)**
 - [Value-Decomposition Networks for Cooperative Multi-Agent Learning(1706)](https://arxiv.org/abs/1706.05296)
 - **(Review) [VAIN: Attentional Multi-agent Predictive Modeling(1706)](https://arxiv.org/abs/1706.06122)**
 - **(Review) [Learning with Opponent-Learning Awareness(1709)](https://arxiv.org/abs/1709.04326)**
 - **(Review) [Emergence Complexity via Multi-Agent Competition(1710)](https://arxiv.org/abs/1710.03748)**
 - [Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments(1710)](https://arxiv.org/abs/1710.03641)
 - **(Review) [A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning(1711)](https://arxiv.org/abs/1711.00832)**

#### 2017 참고
 - [DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker(1701)](https://arxiv.org/abs/1701.01724)
 - [Robust Adversarial Reinforcement Learning(1703)](https://arxiv.org/abs/1703.02702)
 - [Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play(1703)](https://arxiv.org/abs/1703.05407)

### 2018
 - [DiCE: The Infinitely Differentiable Monte-Carlo Estimator(1802)](https://arxiv.org/abs/1802.05098)
 - [Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents](https://arxiv.org/abs/1802.08757)
 - [Modeling Others using Oneself in Multi-Agent Reinforcement Learning(1802)](https://arxiv.org/abs/1802.09640)
 - **(Review) [QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning(1803)](https://arxiv.org/abs/1803.11485)**
 - **(Review) [Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input(1804)](https://arxiv.org/abs/1804.03984)**
 - **(Review) [Emergent Communication through Negotiation(1804)](https://arxiv.org/abs/1804.03980)**
 - **(Review) [Learning Attentional Communication for Multi-Agent Cooperation(1805)](https://arxiv.org/abs/1805.07733)**
 - [Learning to Teach in Cooperative Multiagent Reinforcement Learning(1805)](https://arxiv.org/abs/1805.07830)
 - **(Review) [Learning Policy Representation in Multiagent Systems(1805)](https://arxiv.org/abs/1806.06464)**
 - [Human-level performance in first-person multiplayer games with population-based deep reinforcement learning(1807)](https://arxiv.org/abs/1807.01281)
 - Learning to Coordinate with Coordination Graphs in Repeated Single-State Multi-Agent Decision Problems
 - Learning to act in Decentralized Partially Observable MDPs
 - [Relational Forward Models for Multi-Agent Learning(1809)](https://arxiv.org/abs/1809.11044)
 - [M^3RL: Mind-aware Multi-agent Management Reinforcement Learning(1810)](https://arxiv.org/abs/1810.00147)
 - **(Review) [TarMAC: Targeted Multi-Agent Communication](https://arxiv.org/abs/1810.11187)**
 - [Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning(1811)](https://arxiv.org/abs/1811.01458)
 - **(Review)[Deep Multi-Agent Reinforcement Learning with Relevance Graphs(1811)](https://arxiv.org/abs/1811.12557)**
 - [Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations(1812)](https://arxiv.org/abs/1812.00922)
 - [Learning when to Communicate at Scale in Multiagent Cooperative and Competitive Tasks(1812)](https://arxiv.org/abs/1812.09755)

### 2019
 - [Improving Coordination in Multi-Agent Deep Reinforcement Learning through Memory-driven Communication(1901)](https://arxiv.org/abs/1901.03887)
 - [Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning(1901)](https://arxiv.org/abs/1901.09207)
 - [Learning to Schedule Communication in Multi-agent Reinforcement Learning(1902)](https://arxiv.org/abs/1902.01554)
 - **(Review) [Message-Dropout: An Efficient Training Method for Multi-Agent Reinforcement Learning(1902)](https://arxiv.org/abs/1902.06527)**
 - Robust Multi-Agent Reinforcement Learning via Minimax Deep Deterministic Policy Gradients
 - ...


## Schedule

### Week01
* 자기소개 및 발표자 지정
* Intro


### Week02
* Multiagent Cooperation and Competition with Depp Reinforcement Learning
  - Presenter : 김예찬
  * Paper : https://arxiv.org/abs/1511.08779
  * Material : [1. Multiagent Cooperation and Competition with Depp Reinforcement Learning](https://www.slideshare.net/ssuserbd7730/multiagent-cooperative-and-competition-with-deep-reinforcement-learning)

* Learning to Communicate to Solve Riddles with Deep distributed Recurrent Q-Network
  * Presenter : 김예찬
  * Paper : https://arxiv.org/abs/1602.02672
  * Material : [2. Learning to Communicate to Solve Riddles with Deep distributed Recurrent Q-Network](https://www.slideshare.net/ssuserbd7730/learning-to-communicate-to-solve-riddles-with-deep-distributed-recurrent-qnetworks-128910642)
  

### Week03
* Deep Reinforcement Learning from Self-Play in Imperfect-Information
  - Presenter : 강효림
  * Paper : https://arxiv.org/abs/1603.01121
  * Material : [3. Deep Reinforcement Learning from Self-Play in Imperfect-Information](https://github.com/ModulabsLVNA/MADRL/blob/master/Week03/3.%20Deep%20Reinforcement%20Learning%20from%20Self-Play%20in%20Imperfect-Information.pdf)

* Learning to Communicate with Deep Multi-Agent Reinforcement Learning
  * Presenter : 강효림
  * Paper : https://arxiv.org/abs/1605.06676
  * Material : [4. Learning to Communicate with Deep Multi-Agent Reinforcement Learning](https://github.com/ModulabsLVNA/MADRL/blob/master/Week03/4.%20Learning%20to%20Communicate%20with%20Deep%20Multi-Agent%20Reinforcement%20Learning.pdf)


### Week04
* Learning Multiagent Communication with Backpropagation
  - Presenter : 안홍일
  * Paper : https://arxiv.org/abs/1605.07736
  * Material : [5. Learning Multiagent Communication with Backpropagation](https://github.com/ModulabsLVNA/MADRL/blob/master/Week04/5.%20Learning%20Multiagent%20Communication%20with%20Backpropagation.pdf)

* Cooperative Multi-Agent Control using Deep Reinforcement Learning
  * Presenter : 배영민
  * Paper : http://ala2017.it.nuigalway.ie/papers/ALA2017_Gupta.pdf
  * Material : [6. Cooperative Multi-Agent Control using Deep Reinforcement Learning](https://github.com/ModulabsLVNA/MADRL/blob/master/Week04/6.%20Cooperative%20Multi-Agent%20Control%20using%20Deep%20Reinforcement%20Learning.pdf)


### Week05
* Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning
  - Presenter : 박규봉
  * Paper : 
  * Material : 
  
* Multi-agent Reinforcement Learning in Sequencial Social Dilemma 
  * Presenter : 김예찬
  * Paper : 
  * Material : 


### Week06
* Emergence of Grounded Language in Multi-Agent Populations Games
  - Presenter : 양홍선
  * Paper : 
  * Material : 
  
* Emergence of Language with Multi-agent Games: Learning to Communicate with Sequence of Symbols
  * Presenter : 김예찬
  * Paper : 
  * Material : 
  
* 


### Week07
* Counterfactual Multi-Agent Policy Gradients
  - Presenter : 김예찬
  * Paper : 
  * Material : 
  
* Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments
  * Presenter : 김예찬
  * Paper : 
  * Material : 
  
* 

### Week08
* Learning with Opponent-Learning Awareness
  - Presenter : 박규봉
  * Paper : 
  * Material : 
  
* Emergence Complexity via Multi-Agent Competition
  * Presenter : 김예찬
  * Paper : 
  * Material : 
  
  
### Week09
* A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning
  - Presenter : 강효림
  * Paper : 
  * Material : 
  
* QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning
  * Presenter : 양홍선
  * Paper : 
  * Material : 
  
  
### Week10
* Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input
  - Presenter : 김예찬
  * Paper : 
  * Material : 
  
* Emergence Communication through Negotiation
  * Presenter : 김예찬
  * Paper : 
  * Material : 
  
  
### Week11
* Learning Policy Representation in Multiagent Systems
  - Presenter : 박규봉
  * Paper : 
  * Material : 
  
* Learning to Coordinate with Coordination Graphs in Repeated Single-Stage Multi-Agent Decision
  * Presenter : 김예찬
  * Paper : 
  * Material : 
  
  
